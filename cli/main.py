#!/usr/bin/env python3
from __future__ import annotations

import argparse
import base64
import json
import os
import sys
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timezone
from pathlib import Path

import requests
from dotenv import load_dotenv
from rich.console import Console
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TaskProgressColumn,
    TextColumn,
    TimeElapsedColumn,
)

from cli.schema_to_tandoor import map_schema_to_tandoor

ALLOWED_SUFFIXES = {".jpg", ".jpeg", ".png"}
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_IMAGE_API_URL = "https://api.openai.com/v1/images/generations"
GEMINI_API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Send an image and prompt to the ChatGPT API and store the JSON "
            "response, or convert an existing schema.org Recipe JSON to "
            "Tandoor-compatible JSON."
        ),
    )
    image_group = parser.add_argument_group(
        "image-to-schema",
        "Generate schema.org Recipe JSON from an image or a folder of images",
    )
    image_group.add_argument(
        "--image",
        help="Path to the JPG or PNG image to analyze.",
    )
    image_group.add_argument(
        "--output-dir",
        help="Directory where the JSON response should be written.",
    )
    image_group.add_argument(
        "--image-dir",
        help="Directory containing JPG/PNG files to convert to schema.org Recipe JSON.",
    )

    tandoor_group = parser.add_argument_group(
        "schema-to-tandoor",
        "Convert existing schema.org Recipe JSON to Tandoor JSON and optionally import into Tandoor via API",
    )
    tandoor_group.add_argument(
        "--schema-json",
        help="Path to an existing schema.org Recipe JSON file to convert.",
    )
    tandoor_group.add_argument(
        "--tandoor-out",
        help="Output path for a single Tandoor JSON (default: <schema-stem>-tandoor.json).",
    )
    tandoor_group.add_argument(
        "--schema-dir",
        help="Directory containing schema.org Recipe JSON files to convert and import.",
    )
    tandoor_group.add_argument(
        "--tandoor-json",
        help="Path to an existing Tandoor JSON file to import directly.",
    )
    tandoor_group.add_argument(
        "--tandoor-json-dir",
        help="Directory containing Tandoor JSON files to import directly.",
    )
    parser.add_argument(
        "--tandoor-base-url",
        help="Tandoor base URL, e.g. https://tandoor.example.com (defaults to TANDOOR_BASE_URL env).",
    )
    parser.add_argument(
        "--tandoor-token",
        help="Tandoor API token (defaults to TANDOOR_API_TOKEN env).",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Only write Tandoor JSON files, do not POST to the Tandoor API (import is automatic if TANDOOR_BASE_URL and TANDOOR_API_TOKEN are set).",
    )
    parser.add_argument(
        "--api",
        choices=["openai", "gemini"],
        default=None,
        help="API provider to use (defaults to API_PROVIDER env or openai).",
    )
    parser.add_argument(
        "--model",
        default=None,
        help="Override the model name (defaults to OPENAI_MODEL/GEMINI_MODEL env or provider default).",
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=None,
        help="Maximum completion tokens in the response (optional).",
    )
    parser.add_argument(
        "--concurrency",
        type=int,
        default=None,
        help=(
            "Maximum number of parallel API requests when processing a folder of "
            "images (default from OPENAI_CONCURRENCY/GEMINI_CONCURRENCY env or 2)."
        ),
    )
    parser.add_argument(
        "--no-images",
        action="store_true",
        help="Disable automatic image generation (images are generated by default if OPENAI_API_KEY is set).",
    )
    parser.add_argument(
        "--image-output-dir",
        help="Directory where generated recipe images should be saved (default: same as schema JSON directory).",
    )
    return parser.parse_args()


def validate_image_path(image_path: Path) -> None:
    if not image_path.exists():
        raise SystemExit(f"Image file not found: {image_path}")
    if not image_path.is_file():
        raise SystemExit(f"Image path is not a file: {image_path}")
    if image_path.suffix.lower() not in ALLOWED_SUFFIXES:
        allowed = ", ".join(sorted(ALLOWED_SUFFIXES))
        raise SystemExit(f"Unsupported image type '{image_path.suffix}'. Allowed: {allowed}")


def load_config(provider: str) -> tuple[str, str]:
    load_dotenv()
    if provider == "gemini":
        api_key = os.getenv("GEMINI_API_KEY")
        prompt = os.getenv("GEMINI_PROMPT") or os.getenv("CHATGPT_PROMPT")
        if not api_key:
            raise SystemExit("GEMINI_API_KEY missing. Add it to your environment or .env file.")
    else:  # openai
        api_key = os.getenv("OPENAI_API_KEY")
        prompt = os.getenv("CHATGPT_PROMPT")
        if not api_key:
            raise SystemExit("OPENAI_API_KEY missing. Add it to your environment or .env file.")
    if not prompt:
        raise SystemExit("CHATGPT_PROMPT or GEMINI_PROMPT missing. Add it to your environment or .env file.")
    return api_key, prompt


def build_image_payload(image_path: Path) -> dict:
    data = image_path.read_bytes()
    mime = "image/png" if image_path.suffix.lower() == ".png" else "image/jpeg"
    encoded = base64.b64encode(data).decode("ascii")
    return {
        "type": "image_url",
        "image_url": {"url": f"data:{mime};base64,{encoded}"},
    }


def build_gemini_image_payload(image_path: Path) -> dict:
    data = image_path.read_bytes()
    mime = "image/png" if image_path.suffix.lower() == ".png" else "image/jpeg"
    encoded = base64.b64encode(data).decode("ascii")
    return {
        "inline_data": {
            "mime_type": mime,
            "data": encoded,
        }
    }


def extract_recipe_json(response: dict) -> dict:
    choices = response.get("choices")
    if not choices:
        raise SystemExit("OpenAI response did not contain any choices.")
    message = choices[0].get("message") or {}
    content = message.get("content")

    if isinstance(content, list):
        for part in content:
            if not isinstance(part, dict):
                continue
            if part.get("type") == "output_json" and isinstance(part.get("json"), dict):
                return part["json"]
            if part.get("type") == "text" and part.get("text"):
                try:
                    return json.loads(part["text"])
                except json.JSONDecodeError:
                    continue
    elif isinstance(content, str):
        try:
            return json.loads(content)
        except json.JSONDecodeError as exc:
            raise SystemExit("Model returned non-JSON text.") from exc

    raise SystemExit("OpenAI response did not contain parsable JSON content.")


def call_openai(
    api_key: str,
    prompt: str,
    image_content: dict,
    model: str,
    max_tokens: int | None,
) -> dict:
    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    image_content,
                ],
            }
        ],
    }
    if max_tokens is not None:
        payload["max_completion_tokens"] = max_tokens
    payload["response_format"] = {"type": "json_object"}
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    response = requests.post(
        OPENAI_API_URL,
        headers=headers,
        json=payload,
        timeout=300,
    )
    if response.status_code != 200:
        raise SystemExit(
            f"OpenAI API error {response.status_code}: {response.text}",
        )
    return response.json()


def call_gemini(
    api_key: str,
    prompt: str,
    image_content: dict,
    model: str,
    max_tokens: int | None,
) -> dict:
    url = f"{GEMINI_API_BASE_URL}/models/{model}:generateContent"
    payload = {
        "contents": [
            {
                "parts": [
                    {"text": prompt},
                    image_content,
                ]
            }
        ],
        "generationConfig": {
            "response_mime_type": "application/json",
        },
    }
    if max_tokens is not None:
        payload["generationConfig"]["maxOutputTokens"] = max_tokens
    headers = {
        "Content-Type": "application/json",
    }
    response = requests.post(
        url,
        headers=headers,
        json=payload,
        params={"key": api_key},
        timeout=300,
    )
    if response.status_code != 200:
        raise SystemExit(
            f"Gemini API error {response.status_code}: {response.text}",
        )
    return response.json()


def extract_recipe_json_gemini(response: dict) -> dict:
    candidates = response.get("candidates")
    if not candidates:
        raise SystemExit("Gemini response did not contain any candidates.")
    content = candidates[0].get("content") or {}
    parts = content.get("parts", [])
    
    for part in parts:
        text = part.get("text")
        if text:
            try:
                return json.loads(text)
            except json.JSONDecodeError as exc:
                raise SystemExit("Model returned non-JSON text.") from exc
    
    raise SystemExit("Gemini response did not contain parsable JSON content.")


def build_output_path(image_path: Path, output_dir: Path) -> Path:
    output_dir.mkdir(parents=True, exist_ok=True)
    # Nutze Mikrosekunden im Timestamp, um Kollisionen bei paralleler Verarbeitung zu vermeiden
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S-%f")
    base_name = f"{image_path.stem}-{timestamp}.json"
    return output_dir / base_name


def _process_image(
    image_path: Path,
    output_dir: Path,
    api_key: str,
    prompt: str,
    model: str,
    max_tokens: int | None,
    provider: str,
    progress_task: int | None = None,
    progress: Progress | None = None,
) -> None:
    if progress and progress_task is not None:
        progress.update(
            progress_task,
            description=f"Verarbeite Rezept - {image_path.name}",
        )
    validate_image_path(image_path)

    if provider == "gemini":
        image_payload = build_gemini_image_payload(image_path)
        api_name = "Gemini"
    else:  # openai
        image_payload = build_image_payload(image_path)
        api_name = "ChatGPT"

    if progress and progress_task is not None:
        progress.update(progress_task, description=f"{api_name} analysiert {image_path.name}...")

    if provider == "gemini":
        result = call_gemini(
            api_key=api_key,
            prompt=prompt,
            image_content=image_payload,
            model=model,
            max_tokens=max_tokens,
        )
        recipe_json = extract_recipe_json_gemini(result)
    else:  # openai
        result = call_openai(
            api_key=api_key,
            prompt=prompt,
            image_content=image_payload,
            model=model,
            max_tokens=max_tokens,
        )
        recipe_json = extract_recipe_json(result)

    output_path = build_output_path(image_path, output_dir)
    output_path.write_text(
        json.dumps(recipe_json, indent=2, ensure_ascii=False),
        encoding="utf-8",
    )
    if progress and progress_task is not None:
        progress.update(progress_task, description=f"✓ {image_path.name} abgeschlossen")
    else:
        print(f"Response written to {output_path}")


def _iter_image_files(image_dir: Path) -> list[Path]:
    files: list[Path] = []
    if not image_dir.exists():
        raise SystemExit(f"Image directory or file not found: {image_dir}")
    
    # Wenn es eine Textdatei ist, zeilenweise Bildpfade einlesen
    if image_dir.is_file():
        try:
            with image_dir.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    img_path = Path(line).expanduser().resolve()
                    if img_path.exists() and img_path.is_file():
                        if img_path.suffix.lower() in ALLOWED_SUFFIXES:
                            files.append(img_path)
                        else:
                            print(
                                f"Warnung: Überspringe {img_path} (nicht unterstütztes Format)",
                                file=sys.stderr,
                            )
                    else:
                        print(
                            f"Warnung: Bild nicht gefunden: {img_path}",
                            file=sys.stderr,
                        )
        except Exception as exc:
            raise SystemExit(f"Fehler beim Lesen der Bildliste {image_dir}: {exc}") from exc
        if not files:
            raise SystemExit(f"Keine gültigen Bildpfade in {image_dir} gefunden")
        return files
    
    # Wenn es ein Verzeichnis ist, wie bisher alle Bilder finden
    if not image_dir.is_dir():
        raise SystemExit(f"Image path is neither a directory nor a text file: {image_dir}")
    for suffix in ALLOWED_SUFFIXES:
        files.extend(sorted(image_dir.glob(f"*{suffix}")))
    return files


def _write_error_log(
    failed_images: list[tuple[Path, Exception]],
    output_dir: Path,
) -> tuple[Path, Path]:
    """Schreibe detailliertes Fehler-Log und failed-images.txt.

    Returns:
        Tuple von (error_log_path, failed_images_path)
    """
    # Stelle sicher, dass das Output-Verzeichnis existiert
    # (kann fehlen, wenn Fehler vor build_output_path auftreten)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Nutze Mikrosekunden im Timestamp, um Kollisionen bei paralleler Verarbeitung zu vermeiden
    timestamp = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S-%f")
    error_log_path = output_dir / f"errors-{timestamp}.log"
    failed_images_path = output_dir / f"failed-images-{timestamp}.txt"

    # Detailliertes Fehler-Log schreiben
    with error_log_path.open("w", encoding="utf-8") as log_file:
        log_file.write(f"=== Error Log: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} ===\n\n")
        for img_path, exc in failed_images:
            log_file.write(f"[{datetime.now(timezone.utc).strftime('%H:%M:%S')}] {img_path}\n")
            log_file.write(f"  Error: {type(exc).__name__}: {exc}\n")
            log_file.write("  Traceback:\n")
            # Stacktrace formatieren
            tb_lines = traceback.format_exception(type(exc), exc, exc.__traceback__)
            for line in tb_lines:
                log_file.write(f"    {line}")
            log_file.write("\n")

    # Einfache Liste der fehlgeschlagenen Bildpfade
    with failed_images_path.open("w", encoding="utf-8") as failed_file:
        for img_path, _ in failed_images:
            failed_file.write(f"{img_path}\n")

    return error_log_path, failed_images_path


def _iter_schema_files(schema_dir: Path) -> list[Path]:
    path = schema_dir
    if not path.exists() or not path.is_dir():
        raise SystemExit(f"Schema JSON directory not found: {path}")
    return sorted(path.glob("*.json"))


def _load_tandoor_config(args: argparse.Namespace) -> tuple[str, str]:
    load_dotenv()
    base_url = args.tandoor_base_url or os.getenv("TANDOOR_BASE_URL") or ""
    token = args.tandoor_token or os.getenv("TANDOOR_API_TOKEN") or ""
    if not base_url:
        raise SystemExit("TANDOOR_BASE_URL is required (env or --tandoor-base-url).")
    if not token:
        raise SystemExit("TANDOOR_API_TOKEN is required (env or --tandoor-token).")
    return base_url.rstrip("/"), token


# ============================================================================
# Intelligent Image Generation: Ingredient Transformation Rules
# ============================================================================

# Zutatenkategorien mit Keywords und Standard-Transformationen
INGREDIENT_CATEGORIES = {
    "fish": {
        "keywords": [
            "lachs", "seelachs", "fisch", "forelle", "kabeljau", "scholle",
            "dorsch", "makrele", "thunfisch", "sardine", "hering", "zander",
            "barsch", "karpfen", "aal", "garnelen", "krebs", "muscheln",
            "tintenfisch", "krake", "scampi", "shrimps", "hummer"
        ],
        "default_prep": "gekochtes {name}-Filet",
        "form_keywords": {
            "stück": "in Stücken",
            "filet": "als Filet",
            "würfel": "in Würfeln",
            "streifen": "in Streifen",
            "tranche": "als Tranche"
        },
        "prep_keywords": {
            "gebraten": "gebratenes {name}-Filet",
            "gebacken": "gebackenes {name}-Filet",
            "gedünstet": "gedünstetes {name}-Filet"
        }
    },
    "meat": {
        "keywords": [
            "rind", "rindfleisch", "schwein", "schweinefleisch", "fleisch",
            "steak", "schnitzel", "kotelett", "braten", "schinken", "speck",
            "wurst", "salami", "hackfleisch", "hack", "gehackt", "lamm",
            "lammfleisch", "kalb", "kalbfleisch", "wild", "hase", "reh"
        ],
        "default_prep": "gekochtes {name}",
        "form_keywords": {
            "stück": "in Stücken",
            "würfel": "in Würfeln",
            "streifen": "in Streifen",
            "scheibe": "in Scheiben",
            "hack": "als Hackfleisch"
        },
        "prep_keywords": {
            "gebraten": "gebratenes {name}",
            "gebacken": "gebackenes {name}",
            "gedünstet": "gedünstetes {name}",
            "geschmort": "geschmortes {name}",
            "gegrillt": "gegrilltes {name}"
        }
    },
    "poultry": {
        "keywords": [
            "hähnchen", "huhn", "hühnchen", "hühnerfleisch", "puten",
            "putenfleisch", "ente", "entenbrust", "gans", "wachtel",
            "hühnerbrust", "hühnerschenkel", "flügel"
        ],
        "default_prep": "gekochtes {name}",
        "form_keywords": {
            "stück": "in Stücken",
            "filet": "als Filet",
            "würfel": "in Würfeln",
            "streifen": "in Streifen"
        },
        "prep_keywords": {
            "gebraten": "gebratenes {name}",
            "gebacken": "gebackenes {name}",
            "gedünstet": "gedünstetes {name}",
            "gegrillt": "gegrilltes {name}"
        }
    },
    "vegetable": {
        "keywords": [
            "kartoffel", "möhre", "karotte", "brokkoli", "blumenkohl",
            "zucchini", "paprika", "tomate", "gurke", "spinat", "kohl",
            "weißkohl", "rotkohl", "wirsing", "porree", "lauch", "zwiebel",
            "knoblauch", "spargel", "erbsen", "bohnen", "linsen", "kichererbsen",
            "aubergine", "pilz", "champignon", "sellerie", "fenchel", "kürbis"
        ],
        "default_prep": "gedünstetes {name}",
        "prep_keywords": {
            "stampf": "{name}stampf",
            "püree": "{name}püree",
            "gebraten": "gebratenes {name}",
            "gedünstet": "gedünstetes {name}",
            "gekocht": "gekochtes {name}",
            "roh": "rohes {name}"
        },
        "form_keywords": {
            "stück": "in Stücken",
            "würfel": "in Würfeln",
            "scheibe": "in Scheiben",
            "streifen": "in Streifen"
        }
    },
    "grain": {
        "keywords": [
            "reis", "nudel", "pasta", "spaghetti", "penne", "farfalle",
            "bulgur", "couscous", "quinoa", "hafer", "weizen", "dinkel",
            "haferflocken", "mehl", "semmelbrösel", "panko"
        ],
        "default_prep": "gekochte {name}",
        "prep_keywords": {
            "gekocht": "gekochte {name}",
            "gebraten": "gebratene {name}"
        }
    },
    "dairy": {
        "keywords": [
            "käse", "mozzarella", "gouda", "cheddar", "feta", "ricotta",
            "milch", "sahne", "creme", "joghurt", "quark", "butter",
            "margarine", "schmand", "sauerrahm"
        ],
        "default_prep": "{name}",
        "prep_keywords": {
            "geschmolzen": "geschmolzener {name}",
            "gerieben": "geriebener {name}"
        }
    }
}

# Zubereitungsarten-Mappings
PREPARATION_METHODS = {
    "cooked": ["kochen", "garen", "dünsten", "köcheln", "sieden"],
    "fried": ["braten", "anbraten", "schmoren", "sautieren", "schwenken"],
    "baked": ["backen", "überbacken", "gratinieren"],
    "mashed": ["stampfen", "pürieren", "zerdrücken", "zermatschen"],
    "grilled": ["grillen", "grillieren"],
    "roasted": ["rösten", "anrösten"],
    "raw": ["roh", "frisch", "unverarbeitet"]
}

# Form/Präsentations-Keywords
PRESENTATION_FORMS = {
    "stück": ["stück", "stücke", "stücken", "portion"],
    "filet": ["filet", "filets"],
    "würfel": ["würfel", "würfeln", "gewürfelt"],
    "streifen": ["streifen", "streifchen", "streifig"],
    "scheibe": ["scheibe", "scheiben", "tranche"],
    "hack": ["hack", "hackfleisch", "gehackt", "hacken"],
    "stampf": ["stampf", "stampfen", "gestampft"],
    "püree": ["püree", "pürieren", "püriert"]
}


def _categorize_ingredient(ingredient_name: str) -> str | None:
    """
    Ordnet eine Zutat einer Kategorie zu basierend auf Keywords.
    
    Args:
        ingredient_name: Name der Zutat
        
    Returns:
        Kategorie-ID (z.B. "fish", "meat", "vegetable") oder None
    """
    ingredient_lower = ingredient_name.lower()
    
    for category_id, category_data in INGREDIENT_CATEGORIES.items():
        keywords = category_data.get("keywords", [])
        for keyword in keywords:
            if keyword in ingredient_lower:
                return category_id
    
    return None


def _extract_preparation_methods(recipe: dict) -> set[str]:
    """
    Extrahiert Zubereitungsarten aus Rezeptname, Beschreibung und Anweisungen.
    
    Args:
        recipe: Rezept-Dictionary (schema.org oder Tandoor Format)
        
    Returns:
        Set von erkannten Zubereitungsarten (z.B. {"cooked", "fried"})
    """
    found_methods = set()
    
    # Analysiere Rezeptname
    name = recipe.get("name", "").lower()
    description = recipe.get("description", "").lower()
    
    # Analysiere Anweisungen/Steps
    instructions_text = ""
    steps = recipe.get("steps", []) or recipe.get("recipeInstructions", [])
    if isinstance(steps, list):
        for step in steps:
            if isinstance(step, dict):
                step_text = step.get("text", "") or step.get("name", "") or ""
            elif isinstance(step, str):
                step_text = step
            else:
                step_text = ""
            instructions_text += " " + step_text.lower()
    elif isinstance(steps, str):
        instructions_text = steps.lower()
    
    # Kombiniere alle Texte
    combined_text = f"{name} {description} {instructions_text}".lower()
    
    # Suche nach Zubereitungsarten
    for method_id, keywords in PREPARATION_METHODS.items():
        for keyword in keywords:
            if keyword in combined_text:
                found_methods.add(method_id)
                break
    
    return found_methods


def _extract_presentation_form(recipe_name: str, description: str) -> dict[str, str]:
    """
    Erkennt Form/Präsentation aus Rezeptnamen und Beschreibung.
    
    Args:
        recipe_name: Name des Rezepts
        description: Beschreibung des Rezepts
        
    Returns:
        Dictionary mit Form-Mappings: {form_key: form_description}
    """
    combined_text = f"{recipe_name} {description}".lower()
    found_forms = {}
    
    for form_key, keywords in PRESENTATION_FORMS.items():
        for keyword in keywords:
            if keyword in combined_text:
                found_forms[form_key] = PRESENTATION_FORMS[form_key][0]
                break
    
    return found_forms


def _transform_ingredient_for_image(ingredient_name: str, recipe: dict) -> str:
    """
    Transformiert eine Zutat basierend auf Kategorie, Zubereitungsart und Form
    in ihre zubereitete Form für die Bildgenerierung.
    
    Args:
        ingredient_name: Name der Zutat
        recipe: Vollständiges Rezept-Dictionary
        
    Returns:
        Transformierte Zutatenbeschreibung
    """
    # Kategorisiere Zutat
    category = _categorize_ingredient(ingredient_name)
    if not category:
        # Keine Kategorie gefunden, verwende Original
        return ingredient_name
    
    category_data = INGREDIENT_CATEGORIES[category]
    recipe_name = recipe.get("name", "").lower()
    description = recipe.get("description", "").lower()
    combined_text = f"{recipe_name} {description}".lower()
    
    # Extrahiere Zubereitungsarten
    prep_methods = _extract_preparation_methods(recipe)
    
    # Extrahiere Präsentationsform
    presentation_forms = _extract_presentation_form(recipe_name, description)
    
    # Bestimme Zubereitungsart für diese spezifische Zutat
    prep_keyword = None
    for method_id in prep_methods:
        # Mappe Zubereitungsart zu deutschen Begriffen
        method_keywords = {
            "cooked": "gekocht",
            "fried": "gebraten",
            "baked": "gebacken",
            "mashed": "gestampft",
            "grilled": "gegrillt",
            "roasted": "geröstet",
            "raw": "roh"
        }
        if method_id in method_keywords:
            prep_keyword = method_keywords[method_id]
            break
    
    # Prüfe ob spezifische Zubereitung für diese Zutat im Rezepttext erwähnt wird
    ingredient_lower = ingredient_name.lower()
    specific_prep = None
    prep_keywords = category_data.get("prep_keywords", {})
    for prep_key, prep_template in prep_keywords.items():
        if prep_key in combined_text and any(kw in ingredient_lower for kw in category_data.get("keywords", [])):
            specific_prep = prep_template.format(name=ingredient_name)
            break
    
    # Bestimme Form
    form_suffix = ""
    form_keywords = category_data.get("form_keywords", {})
    for form_key, form_desc in form_keywords.items():
        if form_key in presentation_forms or form_key in combined_text:
            form_suffix = f" {form_desc}"
            break
    
    # Spezielle Behandlung für Gemüse-Stampf/Püree
    if category == "vegetable":
        if "stampf" in combined_text or "püree" in combined_text:
            if "kartoffel" in ingredient_lower:
                return "Kartoffelstampf"
            prep_keywords_veg = category_data.get("prep_keywords", {})
            if "stampf" in prep_keywords_veg:
                return prep_keywords_veg["stampf"].format(name=ingredient_name)
            if "püree" in prep_keywords_veg:
                return prep_keywords_veg["püree"].format(name=ingredient_name)
    
    # Verwende spezifische Zubereitung falls gefunden
    if specific_prep:
        return specific_prep + form_suffix
    
    # Verwende Zubereitungsart aus extrahierten Methoden
    if prep_keyword:
        # Erstelle Transformations-String basierend auf Kategorie
        if category in ("fish", "meat", "poultry"):
            if category == "fish":
                return f"{prep_keyword}es {ingredient_name}-Filet{form_suffix}"
            else:
                return f"{prep_keyword}es {ingredient_name}{form_suffix}"
        elif category == "vegetable":
            return f"{prep_keyword}es {ingredient_name}{form_suffix}"
        elif category == "grain":
            return f"{prep_keyword}e {ingredient_name}{form_suffix}"
    
    # Fallback: Standard-Transformation der Kategorie
    default_prep = category_data.get("default_prep", "{name}")
    transformed = default_prep.format(name=ingredient_name)
    
    # Füge Form hinzu falls vorhanden
    if form_suffix:
        transformed += form_suffix
    
    return transformed


def _generate_recipe_image(
    recipe: dict,
    api_key: str,
    output_path: Path,
    model: str = "dall-e-3",
    size: str = "1024x1024",
) -> Path | None:
    """
    Generate an image for a recipe using DALL-E and save it locally.
    
    Args:
        recipe: Recipe dictionary (schema.org or Tandoor format)
        api_key: OpenAI API key
        output_path: Path where the image should be saved
        model: DALL-E model to use (dall-e-3 or dall-e-2)
        size: Image size (1024x1024, 1792x1024, or 1024x1792 for dall-e-3)
    
    Returns:
        Path to the saved image, or None if generation failed
    """
    # Build a descriptive prompt from the recipe
    # Handle both Tandoor and schema.org formats
    name = recipe.get("name", "Ein Gericht")
    description = recipe.get("description", "")
    
    # Get ingredients (Tandoor uses "ingredients", schema.org uses "recipeIngredient")
    ingredients = recipe.get("ingredients", []) or recipe.get("recipeIngredient", [])
    
    # Extract ingredient names (handle both Tandoor and schema.org formats)
    ingredient_names = []
    if isinstance(ingredients, list):
        for ing in ingredients:
            if isinstance(ing, dict):
                # Tandoor format: {"food": {"name": "..."}, "amount": ..., "unit": ...}
                food = ing.get("food", {})
                if isinstance(food, dict):
                    food_name = food.get("name", "")
                    if food_name:
                        ingredient_names.append(food_name)
                elif isinstance(food, str):
                    ingredient_names.append(food)
            elif isinstance(ing, str):
                # schema.org format: list of strings like "125 g Mehl"
                # Extract just the ingredient name (remove amount/unit)
                # Simple heuristic: take the last significant word(s)
                parts = ing.strip().split()
                # Skip numeric parts and common units at the start
                skip_words = {"g", "kg", "ml", "l", "EL", "TL", "Tasse", "Tassen", "Stück", "Stk"}
                meaningful_parts = []
                for part in parts:
                    # Skip if it's a number or common unit
                    if part.replace(",", ".").replace(".", "").isdigit() or part in skip_words:
                        continue
                    meaningful_parts.append(part)
                if meaningful_parts:
                    # Take last 2-3 words as ingredient name
                    ingredient_name = " ".join(meaningful_parts[-3:])
                    ingredient_names.append(ingredient_name)
                else:
                    # Fallback: use the whole string
                    ingredient_names.append(ing)
    
    # Transform ingredients for better image generation
    transformed_ingredients = []
    for ing_name in ingredient_names[:5]:  # Top 5 ingredients
        transformed = _transform_ingredient_for_image(ing_name, recipe)
        transformed_ingredients.append(transformed)
    
    # Extract preparation methods for prompt enhancement
    prep_methods = _extract_preparation_methods(recipe)
    prep_keywords = []
    if prep_methods:
        method_descriptions = {
            "cooked": "gekocht",
            "fried": "gebraten",
            "baked": "gebacken",
            "mashed": "gestampft",
            "grilled": "gegrillt",
            "roasted": "geröstet"
        }
        for method in prep_methods:
            if method in method_descriptions:
                prep_keywords.append(method_descriptions[method])
    
    # Build prompt
    prompt_parts = [f"Ein appetitliches, professionelles Foto von {name}"]
    if transformed_ingredients:
        main_ingredients = ", ".join(transformed_ingredients)
        prompt_parts.append(f"mit {main_ingredients}")
    if description:
        prompt_parts.append(f"({description[:100]})")  # First 100 chars of description
    
    # Add preparation context if available
    prompt_style = "auf einem weißen Teller, professionelle Food-Fotografie, natürliches Licht, hochwertig"
    if prep_keywords:
        prompt_style += f", {', '.join(prep_keywords)} zubereitet"
    else:
        prompt_style += ", fertig zubereitet"
    
    prompt_parts.append(prompt_style)
    
    prompt = ". ".join(prompt_parts)
    
    # Call DALL-E API
    payload = {
        "model": model,
        "prompt": prompt,
        "size": size,
        "quality": "standard",
        "n": 1,
    }
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    
    try:
        response = requests.post(
            OPENAI_IMAGE_API_URL,
            headers=headers,
            json=payload,
            timeout=60,
        )
        if response.status_code != 200:
            print(
                f"Warning: Failed to generate image for '{name}' "
                f"({response.status_code}): {response.text}",
                file=sys.stderr,
            )
            return None
        
        result = response.json()
        image_url = result.get("data", [{}])[0].get("url")
        
        if not image_url:
            print(
                f"Warning: No image URL in DALL-E response for '{name}'",
                file=sys.stderr,
            )
            return None
        
        # Download the image
        img_response = requests.get(image_url, timeout=30)
        if img_response.status_code != 200:
            print(
                f"Warning: Failed to download generated image for '{name}'",
                file=sys.stderr,
            )
            return None
        
        # Save the image
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_bytes(img_response.content)
        
        return output_path
        
    except Exception as exc:
        print(
            f"Warning: Error generating image for '{name}': {exc}",
            file=sys.stderr,
        )
        return None


def _upload_image_to_tandoor(
    image_path: Path,
    recipe_id: int,
    base_url: str,
    token: str,
) -> bool:
    """
    Upload an image to an existing Tandoor recipe.
    
    Uses PUT request to /api/recipe/{id}/image/ endpoint (apiRecipeImageUpdate).
    
    Args:
        image_path: Path to the image file
        recipe_id: ID of the recipe in Tandoor
        base_url: Tandoor base URL
        token: API token
    
    Returns:
        True if successful, False otherwise
    """
    url = f"{base_url}/api/recipe/{recipe_id}/image/"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/json",
    }
    mime_type = "image/png" if image_path.suffix.lower() == ".png" else "image/jpeg"
    
    try:
        # Try PUT first (apiRecipeImageUpdate)
        with image_path.open("rb") as img_file:
            files = {
                "image": (image_path.name, img_file, mime_type),
            }
            response = requests.put(
                url,
                headers=headers,
                files=files,
                timeout=(10, 60),
            )
            
            if response.status_code in (200, 201):
                return True
        
        # If PUT fails, try POST as fallback
        with image_path.open("rb") as img_file:
            files = {
                "image": (image_path.name, img_file, mime_type),
            }
            response = requests.post(
                url,
                headers=headers,
                files=files,
                timeout=(10, 60),
            )
            
            if response.status_code in (200, 201):
                return True
        
        print(
            f"Warning: Failed to upload image for recipe ID {recipe_id} "
            f"({response.status_code}): {response.text}",
            file=sys.stderr,
            flush=True,
        )
        return False
    except Exception as exc:
        print(
            f"Warning: Error uploading image for recipe ID {recipe_id}: {exc}",
            file=sys.stderr,
            flush=True,
        )
        return False


def _send_to_tandoor(recipe: dict, base_url: str, token: str, image_path: Path | None = None) -> bool:
    """
    Send a recipe to Tandoor API, optionally with an image.
    
    Uses standard JSON upload for the recipe, then uploads image separately if provided.
    
    Args:
        recipe: Recipe dictionary
        base_url: Tandoor base URL
        token: API token
        image_path: Optional path to image file to upload
    
    Returns:
        True if successful, False otherwise
    """
    url = f"{base_url}/api/recipe/"
    
    # Standard JSON upload
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Accept": "application/json",
    }
    
    # Remove image_path from recipe if it exists (it's metadata, not part of recipe)
    recipe_clean = recipe.copy()
    recipe_clean.pop("image_path", None)
    
    response = requests.post(
        url,
        headers=headers,
        json=recipe_clean,
        timeout=(10, 300),
    )
    
    if response.status_code in (200, 201):
        # Recipe was successfully created
        # If we have an image, try to upload it separately (optional/secondary operation)
        if image_path and image_path.exists():
            try:
                result = response.json()
                recipe_id = result.get("id") or result.get("pk")
                if recipe_id:
                    print(f"Recipe created with ID {recipe_id}, uploading image...", flush=True)
                    image_upload_success = _upload_image_to_tandoor(image_path, recipe_id, base_url, token)
                    if not image_upload_success:
                        print(
                            f"Warning: Recipe created but image upload failed for recipe ID {recipe_id}",
                            file=sys.stderr,
                            flush=True,
                        )
                        # Don't return False - recipe was successfully created, image upload is optional
                else:
                    print(
                        f"Warning: Recipe created but could not extract recipe ID for image upload",
                        file=sys.stderr,
                        flush=True,
                    )
                    # Don't return False - recipe was successfully created
            except Exception as exc:
                print(
                    f"Warning: Could not extract recipe ID for image upload: {exc}",
                    file=sys.stderr,
                    flush=True,
                )
                # Don't return False - recipe was successfully created
        return True

    print(
        f"Failed to import recipe '{recipe.get('name', '')}' "
        f"({response.status_code}): {response.text}",
        file=sys.stderr,
        flush=True,
    )
    return False


def _process_single_recipe(task_data: dict) -> tuple[bool, str]:
    """
    Verarbeitet ein einzelnes Rezept: Konvertierung, Bildgenerierung, JSON, Upload.
    
    Args:
        task_data: Dict mit allen benötigten Parametern:
            - schema_recipe: dict
            - schema_file: Path
            - recipe_index: int
            - total_recipes_in_file: int
            - keyword_config: list[dict] | None
            - should_generate_images: bool
            - image_output_dir: Path | None
            - image_api_key: str | None
            - should_import: bool
            - base_url: str
            - token: str
            - tandoor_out: str | None (from args)
            - schema_files: list[Path] (for output path determination)
    
    Returns:
        (success: bool, message: str)
    """
    try:
        schema_recipe = task_data["schema_recipe"]
        schema_file = task_data["schema_file"]
        recipe_index = task_data["recipe_index"]
        total_recipes_in_file = task_data["total_recipes_in_file"]
        keyword_config = task_data["keyword_config"]
        should_generate_images = task_data["should_generate_images"]
        image_output_dir = task_data["image_output_dir"]
        image_api_key = task_data["image_api_key"]
        should_import = task_data["should_import"]
        base_url = task_data["base_url"]
        token = task_data["token"]
        tandoor_out = task_data.get("tandoor_out")
        schema_files = task_data["schema_files"]
        
        # 1. Konvertierung
        tandoor = map_schema_to_tandoor(schema_recipe)
        
        # Add keywords
        if keyword_config:
            tandoor["keywords"] = keyword_config
        
        recipe_name = tandoor.get("name", "Rezept")
        print(f"[{recipe_name}] Starte Verarbeitung...", flush=True)
        
        # 2. Bildgenerierung (falls aktiviert)
        image_path = None
        if should_generate_images and image_output_dir:
            print(f"[{recipe_name}] Generiere Bild...", flush=True)
            # Use recipe name for image filename, fallback to schema file stem + index
            recipe_name_safe = "".join(c for c in recipe_name if c.isalnum() or c in (" ", "-", "_")).strip()[:50]
            if not recipe_name_safe:
                recipe_name_safe = schema_file.stem
            # Add index if multiple recipes in one file
            if total_recipes_in_file > 1:
                image_filename = f"{recipe_name_safe}-{recipe_index}.png"
            else:
                image_filename = f"{recipe_name_safe}.png"
            image_path = image_output_dir / image_filename
            
            generated_path = _generate_recipe_image(
                recipe=tandoor,
                api_key=image_api_key,
                output_path=image_path,
            )
            if generated_path:
                image_path = generated_path
                print(f"[{recipe_name}] Bild gespeichert: {image_path}", flush=True)
            else:
                image_path = None
                print(f"[{recipe_name}] Warnung: Bildgenerierung fehlgeschlagen", file=sys.stderr, flush=True)
        
        # 3. JSON schreiben
        # Determine output path
        if tandoor_out and len(schema_files) == 1 and total_recipes_in_file == 1:
            out_path = Path(tandoor_out).expanduser().resolve()
        else:
            # If multiple recipes in one file, add index to filename
            if total_recipes_in_file > 1:
                out_path = schema_file.with_name(f"{schema_file.stem}-{recipe_index}-tandoor.json")
            else:
                out_path = schema_file.with_name(f"{schema_file.stem}-tandoor.json")
        
        # Remove image_path from recipe before writing JSON (it's only needed for API upload)
        tandoor_clean = tandoor.copy()
        tandoor_clean.pop("image_path", None)
        
        out_path.write_text(
            json.dumps(tandoor_clean, indent=2, ensure_ascii=False),
            encoding="utf-8",
        )
        print(f"[{recipe_name}] JSON geschrieben: {out_path}", flush=True)
        
        # 4. Upload (falls aktiviert)
        if should_import:
            print(f"[{recipe_name}] Upload zu Tandoor...", flush=True)
            upload_success = _send_to_tandoor(tandoor, base_url=base_url, token=token, image_path=image_path)
            if upload_success:
                print(f"[{recipe_name}] ✓ Upload erfolgreich", flush=True)
            else:
                print(f"[{recipe_name}] ✗ Upload fehlgeschlagen", file=sys.stderr, flush=True)
                return (False, f"{recipe_name} - Upload fehlgeschlagen")
        
        return (True, f"{recipe_name} - JSON: {out_path}")
        
    except Exception as exc:
        recipe_name = task_data.get("schema_recipe", {}).get("name", "Unknown")
        return (False, f"{recipe_name}: {exc}")


def main() -> None:
    args = parse_args()
    has_image_mode = bool(args.image or args.image_dir)
    has_schema_mode = bool(args.schema_json or args.schema_dir)
    has_tandoor_import_mode = bool(args.tandoor_json or args.tandoor_json_dir)

    active_modes = sum(
        1 for flag in (has_image_mode, has_schema_mode, has_tandoor_import_mode) if flag
    )
    if active_modes != 1:
        raise SystemExit(
            "Choose exactly one mode:\n"
            "- image-to-schema (--image/--image-dir)\n"
            "- schema-to-tandoor (--schema-json/--schema-dir)\n"
            "- tandoor-import (--tandoor-json/--tandoor-json-dir)",
        )

    # Mode 1: schema.org Recipe JSON -> Tandoor JSON (+ optional import)
    if has_schema_mode:
        if args.schema_json and args.schema_dir:
            raise SystemExit("Use either --schema-json or --schema-dir, not both.")

        if args.schema_dir:
            schema_dir = Path(args.schema_dir).expanduser().resolve()
            schema_files = _iter_schema_files(schema_dir)
            if not schema_files:
                raise SystemExit(
                    f"No schema.org Recipe JSON files found in directory: {schema_dir}",
                )
        else:
            schema_path = Path(args.schema_json).expanduser().resolve()
            if not schema_path.exists():
                raise SystemExit(f"Schema JSON file not found: {schema_path}")
            schema_files = [schema_path]

        # Auto-detect if we should import to Tandoor (if credentials are available)
        base_url = token = ""
        should_import = not args.dry_run
        
        # Configure keywords for Tandoor API
        # Default IDs: Hello Fresh (21), ✨ AI (11)
        # Format expected by API: [{"id": 0, "name": "string", "description": "string"}]
        # Can be overridden via TANDOOR_KEYWORD_IDS environment variable (comma-separated: "id1,id2")
        keyword_config = [
            {"id": 21, "name": "Hello Fresh", "description": ""},
            {"id": 11, "name": "✨ AI", "description": ""},
        ]
        load_dotenv()
        keyword_ids_str = os.getenv("TANDOOR_KEYWORD_IDS")
        if keyword_ids_str:
            try:
                keyword_ids = [int(id_str.strip()) for id_str in keyword_ids_str.split(",") if id_str.strip()]
                if len(keyword_ids) >= 2:
                    keyword_config = [
                        {"id": keyword_ids[0], "name": "Hello Fresh", "description": ""},
                        {"id": keyword_ids[1], "name": "✨ AI", "description": ""},
                    ]
                else:
                    print(
                        f"Warning: TANDOOR_KEYWORD_IDS should contain at least 2 IDs (comma-separated). "
                        f"Got {len(keyword_ids)}. Using default keyword IDs.",
                        file=sys.stderr,
                    )
            except ValueError:
                print(
                    f"Warning: Invalid TANDOOR_KEYWORD_IDS format '{keyword_ids_str}'. "
                    "Expected comma-separated integers (e.g., '21,11'). Using default keyword IDs.",
                    file=sys.stderr,
                )
        if should_import:
            try:
                base_url, token = _load_tandoor_config(args)
            except SystemExit as exc:
                # Credentials not available, skip import
                should_import = False
                if len(schema_files) == 1:
                    # Preserve the specific error message from _load_tandoor_config
                    error_msg = str(exc) if exc.args else "Tandoor credentials not found"
                    print(f"Note: {error_msg}, skipping API import (use --dry-run to suppress)", file=sys.stderr, flush=True)

        # Auto-detect if we should generate images (if OPENAI_API_KEY is available)
        should_generate_images = not args.no_images
        image_api_key = None
        if should_generate_images:
            load_dotenv()
            image_api_key = os.getenv("OPENAI_API_KEY")
            if not image_api_key:
                should_generate_images = False
                print("Note: OPENAI_API_KEY not found, skipping image generation (use --no-images to suppress)", file=sys.stderr)

        # Determine image output directory
        image_output_dir = None
        if should_generate_images:
            if args.image_output_dir:
                image_output_dir = Path(args.image_output_dir).expanduser().resolve()
            else:
                # Default to same directory as schema files
                if args.schema_dir:
                    image_output_dir = Path(args.schema_dir).expanduser().resolve()
                else:
                    image_output_dir = Path(args.schema_json).expanduser().resolve().parent
            image_output_dir.mkdir(parents=True, exist_ok=True)
        
        # Get concurrency setting for parallel processing
        load_dotenv()
        concurrency_str = os.getenv("RECIPE_PROCESSING_CONCURRENCY", "5")
        try:
            concurrency = int(concurrency_str)
        except ValueError:
            print(
                f"Warning: Invalid RECIPE_PROCESSING_CONCURRENCY value '{concurrency_str}'. "
                "Expected an integer. Using default value of 5.",
                file=sys.stderr,
                flush=True,
            )
            concurrency = 5
        concurrency = max(1, min(concurrency, 20))
        
        # Phase 1: Collect all recipes into tasks
        tasks = []
        for schema_file in schema_files:
            with schema_file.open("r", encoding="utf-8") as f:
                schema_data = json.load(f)
            
            # Handle both single recipe dict and list of recipes
            if isinstance(schema_data, list):
                recipes_to_process = schema_data
            elif isinstance(schema_data, dict):
                recipes_to_process = [schema_data]
            else:
                print(
                    f"Warning: Unexpected JSON structure in {schema_file}, skipping...",
                    file=sys.stderr,
                )
                continue
            
            for recipe_index, schema_recipe in enumerate(recipes_to_process):
                if not isinstance(schema_recipe, dict):
                    print(
                        f"Warning: Recipe in {schema_file} is not a dictionary, skipping...",
                        file=sys.stderr,
                    )
                    continue
                
                tasks.append({
                    "schema_recipe": schema_recipe,
                    "schema_file": schema_file,
                    "recipe_index": recipe_index,
                    "total_recipes_in_file": len(recipes_to_process),
                    "keyword_config": keyword_config,
                    "should_generate_images": should_generate_images,
                    "image_output_dir": image_output_dir,
                    "image_api_key": image_api_key,
                    "should_import": should_import,
                    "base_url": base_url,
                    "token": token,
                    "tandoor_out": args.tandoor_out,
                    "schema_files": schema_files,
                })
        
        if not tasks:
            print("No recipes to process.", file=sys.stderr)
            return
        
        # Phase 2: Parallel execution
        results = []
        print(f"Verarbeite {len(tasks)} Rezept(e) mit {concurrency} parallelen Worker(s)...\n", flush=True)
        if len(tasks) == 1 or concurrency == 1:
            # Sequential processing for single task or concurrency=1
            for task in tasks:
                success, message = _process_single_recipe(task)
                results.append((success, message))
                if success:
                    print(f"✓ {message}", flush=True)
                else:
                    print(f"✗ {message}", file=sys.stderr, flush=True)
        else:
            # Parallel processing
            with ThreadPoolExecutor(max_workers=concurrency) as executor:
                futures = {executor.submit(_process_single_recipe, task): task for task in tasks}
                for future in as_completed(futures):
                    success, message = future.result()
                    results.append((success, message))
                    # Status wird bereits in _process_single_recipe() ausgegeben
                    # Hier nur finale Bestätigung
                    if not success:
                        print(f"✗ {message}", file=sys.stderr, flush=True)
        
        # Phase 3: Summary
        success_count = sum(1 for s, _ in results if s)
        print(f"\nFertig: {success_count}/{len(results)} Rezepte erfolgreich verarbeitet", flush=True)
        if success_count < len(results):
            print(f"Warnung: {len(results) - success_count} Rezepte fehlgeschlagen", file=sys.stderr, flush=True)

        return

    # Mode 2: bereits konvertierte Tandoor JSON direkt importieren
    if has_tandoor_import_mode:
        if args.tandoor_json and args.tandoor_json_dir:
            raise SystemExit("Use either --tandoor-json or --tandoor-json-dir, not both.")

        if args.dry_run:
            # Kein API-Call, nur anzeigen, was importiert würde.
            if args.tandoor_json_dir:
                base_dir = Path(args.tandoor_json_dir).expanduser().resolve()
                files = sorted(base_dir.glob("*.json"))
            else:
                files = [Path(args.tandoor_json).expanduser().resolve()]

            for tandoor_file in files:
                print(f"[dry-run] Would import Tandoor JSON: {tandoor_file}")
            return

        base_url, token = _load_tandoor_config(args)

        if args.tandoor_json_dir:
            base_dir = Path(args.tandoor_json_dir).expanduser().resolve()
            files = sorted(base_dir.glob("*.json"))
            if not files:
                raise SystemExit(f"No Tandoor JSON files found in directory: {base_dir}")
        else:
            tandoor_path = Path(args.tandoor_json).expanduser().resolve()
            if not tandoor_path.exists():
                raise SystemExit(f"Tandoor JSON file not found: {tandoor_path}")
            files = [tandoor_path]

        for tandoor_file in files:
            with tandoor_file.open("r", encoding="utf-8") as f:
                recipe = json.load(f)
            
            # Check if recipe has an image_path and try to load it
            image_path = None
            image_path_str = recipe.get("image_path")
            if image_path_str:
                image_path = Path(image_path_str).expanduser().resolve()
                if not image_path.exists():
                    print(
                        f"Warning: Image path '{image_path}' from recipe not found, skipping image upload",
                        file=sys.stderr,
                    )
                    image_path = None
            
            ok = _send_to_tandoor(recipe, base_url=base_url, token=token, image_path=image_path)
            if ok:
                print(f"Imported Tandoor JSON from {tandoor_file}")

        return

    # Mode 3: image -> schema.org Recipe JSON via ChatGPT
    if not has_image_mode or not args.output_dir:
        raise SystemExit(
            "For image processing, provide --output-dir and either --image or --image-dir.",
        )

    if args.image and args.image_dir:
        raise SystemExit("Use either --image or --image-dir, not both.")

    output_dir = Path(args.output_dir).expanduser().resolve()

    if args.image_dir:
        image_dir = Path(args.image_dir).expanduser().resolve()
        image_files = _iter_image_files(image_dir)
        if not image_files:
            raise SystemExit(f"No JPG/PNG files found in directory: {image_dir}")
    else:
        image_path = Path(args.image).expanduser().resolve()
        image_files = [image_path]

    # Determine API provider
    provider = args.api or os.getenv("API_PROVIDER", "openai")
    if provider not in ("openai", "gemini"):
        raise SystemExit(f"Invalid API provider: {provider}. Must be 'openai' or 'gemini'.")

    api_key, prompt = load_config(provider)

    # Set default model based on provider
    if args.model:
        model = args.model
    elif provider == "gemini":
        model = os.getenv("GEMINI_MODEL", "gemini-1.5-pro")
    else:  # openai
        model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # Begrenze parallele Requests, um Rate Limits berücksichtigen zu können.
    # Dabei explizit zwischen None (nicht gesetzt) und 0 unterscheiden.
    if args.concurrency is not None:
        concurrency = args.concurrency
    else:
        env_key = "GEMINI_CONCURRENCY" if provider == "gemini" else "OPENAI_CONCURRENCY"
        concurrency = int(os.getenv(env_key, "2"))
    concurrency = max(1, concurrency)

    console = Console()
    num_images = len(image_files)

    # Progress-Anzeige mit Rich
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        main_task = progress.add_task(
            f"Verarbeite {num_images} Rezeptbilder...",
            total=num_images,
        )

        if len(image_files) == 1 or concurrency == 1:
            # Einzelne Verarbeitung
            for idx, image_path in enumerate(image_files):
                task_id = progress.add_task(
                    f"Verarbeite Rezept {idx + 1}/{num_images} - {image_path.name}",
                    total=1,
                )
                try:
                    _process_image(
                        image_path=image_path,
                        output_dir=output_dir,
                        api_key=api_key,
                        prompt=prompt,
                        model=model,
                        max_tokens=args.max_tokens,
                        provider=provider,
                        progress_task=task_id,
                        progress=progress,
                    )
                    progress.update(task_id, completed=1)
                    progress.update(main_task, advance=1)
                except Exception as exc:  # noqa: BLE001
                    progress.update(
                        task_id,
                        description=f"✗ Fehler: {image_path.name}",
                        completed=1,
                    )
                    progress.update(main_task, advance=1)
                    # Fehler-Log schreiben
                    error_log_path, failed_images_path = _write_error_log(
                        [(image_path, exc)],
                        output_dir,
                    )
                    console.print(f"\n[red]Fehler beim Verarbeiten von {image_path.name}:[/red] {exc}")
                    console.print(f"[yellow]Fehlgeschlagenes Bild:[/yellow] {failed_images_path}")
                    console.print(f"[yellow]Detaillierte Fehler:[/yellow] {error_log_path}")
                    raise SystemExit(1) from exc
        else:
            # Parallele Verarbeitung
            had_errors = False
            failed_images: list[tuple[Path, Exception]] = []
            task_map: dict[Path, int] = {}

            # Tasks für alle Bilder erstellen
            for idx, image_path in enumerate(image_files):
                task_id = progress.add_task(
                    f"Warte auf Verarbeitung - {image_path.name}",
                    total=1,
                )
                task_map[image_path] = task_id

            with ThreadPoolExecutor(max_workers=concurrency) as executor:
                future_to_image = {
                    executor.submit(
                        _process_image,
                        image_path=image_path,
                        output_dir=output_dir,
                        api_key=api_key,
                        prompt=prompt,
                        model=model,
                        max_tokens=args.max_tokens,
                        provider=provider,
                        progress_task=task_map[image_path],
                        progress=progress,
                    ): image_path
                    for image_path in image_files
                }

                for future in as_completed(future_to_image):
                    img = future_to_image[future]
                    task_id = task_map[img]
                    try:
                        future.result()
                        progress.update(task_id, completed=1)
                        progress.update(main_task, advance=1)
                    except Exception as exc:  # noqa: BLE001
                        had_errors = True
                        failed_images.append((img, exc))
                        progress.update(
                            task_id,
                            description=f"✗ Fehler: {img.name}",
                            completed=1,
                        )
                        progress.update(main_task, advance=1)

            if had_errors:
                # Fehler-Logs schreiben
                error_log_path, failed_images_path = _write_error_log(
                    failed_images,
                    output_dir,
                )
                console.print("\n[red]Fehler beim Verarbeiten einiger Bilder:[/red]")
                for img, exc in failed_images:
                    console.print(f"  [red]✗[/red] {img}: {exc}")
                console.print(f"\n[yellow]Fehlgeschlagene Bilder:[/yellow] {failed_images_path}")
                console.print(f"[yellow]Detaillierte Fehler:[/yellow] {error_log_path}")
                console.print(
                    f"\n[yellow]Tipp:[/yellow] Erneut versuchen mit: "
                    f'python -m cli.main --image-dir "{failed_images_path}" --output-dir "{output_dir}"'
                )
                raise SystemExit(1)

    # Erfolgsmeldung
    console.print(f"\n[green]✓ Fertig! {num_images} Rezept(e) erfolgreich verarbeitet.[/green]")


if __name__ == "__main__":
    main()

